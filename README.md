# Adaptive Dual-Branch Fusion: Enhancing Infrared-Visible Image Integration via Cross-Modality Learning

![整体框架](C:\Users\PC\Documents\论文图片\整体框架.png)

**Abstract:**In the realm of image processing, the integration of infrared and visible imagery presents a significant challenge due to the need to balance thermal target highlighting with rich texture details. This study introduces ACDFuse, an Adaptive Cross-Modality Dual-Branch Fusion Network, designed to address this challenge by jointly modelling shared and unique features across modalities. The framework comprises a dual-branch encoder, incorporating a Serially Enhanced Representation Transformer Encoder for global semantic consistency and an Invertible Neural Network Encoder for modality-specific details. Adaptive and hierarchical fusion mechanisms, including an Adaptive Position-aware Cross Attention module and a Hierarchical Fusion Layer, facilitate precise alignment and complementary integration of cross-modal features. Extensive experiments on multiple public datasets demonstrate that ACDFuse outperforms state-of-the-art methods across both qualitative and quantitative evaluations, while consistently enhancing object detection performance, thereby validating its robustness and generalization capability.

**We are currently submitting to The Visual Computer journal, and will provide the full code in the future.**
